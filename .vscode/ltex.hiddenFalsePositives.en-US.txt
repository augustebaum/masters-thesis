{"rule":"COMMA_COMPOUND_SENTENCE_2","sentence":"^\\QIn this case the model could generalize poorly and the explanation could therefore be misleading.\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\QThe argument could also be made that CFX also have a realism constraint , although that can be the case for adversarial perturbations too: if the perturbation is imperceptible, then the perturbed input is realistic since it is close to a real input point.\\E$"}
{"rule":"COMMA_COMPOUND_SENTENCE_2","sentence":"^\\QBecause of how ubiquitous AI is becoming, XAI research is also blossoming and the research landscape is vast.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Qenglish backrefpage = page,backrefpages = pages,\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\Qenglish backrefpage = page,backrefpages = pages,\\E$"}
{"rule":"ENGLISH_WORD_REPEAT_RULE","sentence":"^\\QIntro\nContext\nExplain the problem of explainable AI, differentiate between global and local explanations, compare and contrast different local methods (advantages and disadvantages):\nAttribution methods\nLocal approximation methods\nRule-based\nCFX\nCFX\nGiven the previous discussion CFX are attractive, but they suffer from certain issues: having to generate realistic (in-distribution) points, the different goals that CFX have can interfere with each other, and being realistic is not always enough.\\E$"}
{"rule":"POSSESSIVE_APOSTROPHE","sentence":"^\\QNonlinear independent components estimation.\\E$"}
{"rule":"THE_SUPERLATIVE","sentence":"^\\QSince the gradient gives the direction of steepest ascent, going in the opposite direction is the best strategy to decrease \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Q\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q generate a diverse set of CFs by gradient descent, solving for \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q candidate CFs at the same time \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q.\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\QWe run our experiment on the datasets described in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, namely , , and .\\E$"}
{"rule":"DOUBLE_PUNCTUATION","sentence":"^\\QWe run our experiment on the datasets described in \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, namely , , and .\\E$"}
{"rule":"DOUBLE_PUNCTUATION","sentence":"^\\Q../Figures/validity_losses.tex Validity rate means with their standard error.\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\QThis is problematic when it comes to trustworthiness of the explanations: for example, in , the CF path never actually goes through the explained input, even when setting the shift factor \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\QLS to zero.\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\QAs expected, the validity rate achieved by is generally much more acceptable than that of , across all losses.\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\QTo make better sense of our findings, we also plot our various losses and their gradients on .\\E$"}
