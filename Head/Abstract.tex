\begin{abstract}
\addchaptertocentry{\abstractname} % Add the abstract to the table of contents

The problem of explainability hinders the use of machine learning: in some applications justifying a model's decisions is critical to ensure trustworthiness, while in others, it is set to become a legal necessity.
For a given input-output pair, counterfactual explanations address this need by providing an answer to the question "What would it take for the model to change its mind?".
Such an explanation clearly shows which features are determinant to the model, but depending on the circumstance, it also shows an end-user how to obtain a more desirable model outcome.
However, if the counterfactual looks too different from its original point, this can affect the trustworthiness of the explanation itself: unfortunately, the current methods usually do not display the \emph{progression} that leads from the explained input to its counterfactual.

\ls{} was introduced to address this issue: in this technique, the input is perturbed \emph{continuously} towards a target class.
However, so far this technique has been applied mostly to binary classification problems on images, and for good reason: image explanations are easily understandable by humans, so objective quality metrics matter less than for other domains, such as tabular data.

Thus, our contributions are as follows: firstly, we apply \ls{} to (numerical) tabular data.
We are lead to search for objective metrics for the quality of counterfactuals, because rows of data cannot be judged intuitively by a human the way images can.
Secondly, we extend \ls{} to multi-class problems, where targeting a particular class is not the same as simply moving a point away from its current class; we experiment with different loss functions to maximize the probability of reaching the target class.
Thirdly, we propose a variation to \ls{} to ensure paths satisfy certain interpretability constraints, \eg{} the path should only go through \emph{realistic} points.
Finally, we study the robustness of our proposed method by using it with nonsensical constraints.


\end{abstract}