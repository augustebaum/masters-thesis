\documentclass[../main.tex]{subfiles}
\graphicspath{{\subfix{../Figures/}}}

\begin{document}

\chapter{Methods}
\label{ch:methods}

\section{Problem 1: Multi-class extension}

\subsection{Problem statement}

The authors of \ls{} solve the following problem:

Let $f: \R^\inputdim \to [0, 1]$ be a binary classifier such that $f(x)$ outputs the predicted probability of $x$ being in class 1.
Let $x$ be a point that is predicted to be of class 0, \ie{} such that $f(x) < \frac{1}{2}$.
Find the trajectory of quickest class change for $x$; that is, a path starting at (or around) $x$ and ending at a point $\CF{x}$ for which $f(\CF{x}) > \frac{1}{2}$ such that the path is sufficiently short.

They propose building a latent representation $\autoencoder = (\enc, \dec)$, letting $z = \enc(x)$ and computing the gradient of the classifier in that latent space:
$\nabla_z f(\dec(z))$.

In the case of a binary classifier that outputs just one scalar, this might be sufficient. However, in multi-class problems where $f$ outputs a vector in $\R^\outputdim$ there are several possible choices for the gradient computation.
We formulate the problem as follows:

Let $f: \R^\inputdim \to \R^\outputdim$ be a multi-class classifier such that $f(x)$ outputs logits which can be transformed into a probability mass for the predicted class of $x$, \eg{} by a $\mathrm{softmax}$.
Consider a latent representation $\autoencoder = (\enc, \dec)$ of the input space. 
Let $z = \enc(x)$.
Find a validity loss $\lossval$ such that
$\nabla_z \lossval$ gives rise to a class-changing path in input space.

\subsection{Proposed solutions}

Note that this extension to the multi-class setting means that we have a choice to specify a given target class: we might also prefer to simply change the class, without preference of target class. In our analysis we focus on the case where a target class is specified.

At first glance, it seems that $\lossval = -f(\dec(z))_\target$ (the component of $f(\dec(z))$ corresponding to class $\target$) could be a satisfactory generalization: minimizing this loss, is equivalent to maximizing $f(\dec(z))_\target$.
However, one issue with this choice of $\lossval$ is its output domain: $[-1, 0]$, which is small. This means that computing gradients computed from loss could potentially be very small. By contrast, a typical loss function used in classification tasks (such as the cross-entropy) often includes a logarithm so that the loss can change more rapidly which promotes larger gradients. \citenote{}
Hence, we use the cross-entropy instead: $$\lossval = -\ce(f(\dec(z)), y_\target).$$
We call this validity loss \method{TargetLoss}.

There are other possible variants. For example, one might wish to specify that, if not able to get near the target class, the path should at least get away from the source class. This can be included as follows:
$$\lossval = -\ce(f(\dec(z)), y_\target) + \ce(f(\dec(z)), y_\source).$$
We call this variant \method{BinaryStretchLoss}.

Taking this idea further, one might wish that the path should get away from all classes that are not the target, which we could model as follows:
$$\lossval = -\ce(f(\dec(z)), y_\target) + \sum_{c \neq \target} \ce(f(\dec(z)), y_c).$$
We call this \method{StretchLoss}. 

% ---

\section{Problem 2: Path regularization}

\subsection{Problem statement}

A typical requirement on a counterfactual $\CF{x}$ for an input $x$ might be $\norm{\CF{x} - x}$ is small, where $\norm{\cdot}$ is the $L_1$ norm for example.
While this makes sense for methods that produce a discrete set of counterfactuals, we focus on methods that produce continuous explanation paths, hence we wish to extend these requirements to suit this goal.
For instance, in the case of distance, we might wish that the endpoint of the path be close to the starting point, but also that \emph{on the whole} the path stay as close as possible to the starting point.

In the case of gradient-descent optimization paths, this can be addressed by placing these constraints in the loss function during the computation of the next step: this is the case in \revise{}, where the loss function includes the $L_1$ distance \cite{joshiRealistic2019}.

However, for \ls{} this option is not optimal because the gradient is only computed once: even though the first step might be in the right direction, it might be that the whole path could go in the wrong direction, because the information carried by the gradient is less relevant the further away we go from the input.
In other words, we would not be optimizing over the path, but only over the first step of the path.

In the case of gradient-descent methods it makes sense to use losses that take a $z_t$ as input, but how could we constrain a whole path $(z_t)_{t=1}^T$?

\subsection{Proposed solution}




\end{document}